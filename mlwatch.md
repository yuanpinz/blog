---
layout: article
title: Your Daily (or Maybe Monthly) Dose of
key: page-mlwatch 
aside:
    toc: true
---

# Machine Learning Researches

## 2021-12-01

### Yannic Kilcher: [Sparse is Enough in Scaling Transformers (aka Terraformer)](https://youtu.be/hgSGHusDx7M)

### :star:DeepMind: [Exploring the beauty of pure mathematics in novel ways](https://deepmind.com/blog/article/exploring-the-beauty-of-pure-mathematics-in-novel-ways)

### Synced: [NeurIPS 2021 Announces Its 6 Outstanding Paper Awards, 2 Datasets and Benchmarks Track Best Paper Awards, and the Test of Time Award](https://syncedreview.com/2021/12/01/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-156/)

## 2021-11-30

### :star:MARKTECHPOST: [Microsoft Researchers Unlock New Avenues In Image-Generation Research With Manifold Matching Via Metric Learning](https://www.marktechpost.com/2021/11/30/microsoft-researchers-unlock-new-avenues-in-image-generation-research-with-manifold-matching-via-metric-learning/?utm_source=rss&utm_medium=rss&utm_campaign=microsoft-researchers-unlock-new-avenues-in-image-generation-research-with-manifold-matching-via-metric-learning)
## 2021-11-28

### MARKTECHPOST: [Google Research Open-Sources ‘SAVi’: An Object-Centric Architecture That Extends The Slot Attention Mechanism To Videos](https://www.marktechpost.com/2021/11/28/google-research-open-sources-savi-an-object-centric-architecture-that-extends-the-slot-attention-mechanism-to-videos/?utm_source=rss&utm_medium=rss&utm_campaign=google-research-open-sources-savi-an-object-centric-architecture-that-extends-the-slot-attention-mechanism-to-videos)

## 2021-11-27

### MARKTECHPOST: [Apple Researchers Propose A Method For Reconstructing Training Data From Diverse Machine Learning Models By Ensemble Inversion](https://www.marktechpost.com/2021/11/27/apple-researchers-propose-a-method-for-reconstructing-training-data-from-diverse-machine-learning-models-by-ensemble-inversion/?utm_source=rss&utm_medium=rss&utm_campaign=apple-researchers-propose-a-method-for-reconstructing-training-data-from-diverse-machine-learning-models-by-ensemble-inversion)
## 2021-11-22

### Synced: [Microsoft Asia’s Swin Transformer V2 Scales the Award-Winning ViT to 3 Billion Parameters and Achieves SOTA Performance on Vision Benchmarks](https://syncedreview.com/2021/11/22/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-149/)

### Google AI: [Predicting Text Selections with Federated Learning](http://ai.googleblog.com/2021/11/predicting-text-selections-with.html)

## 2021-11-19

### MARKTECHPOST: [Imperial College London Researchers Propose A Novel Randomly Connected Neural Network For Self-Supervised Monocular Depth Estimation In Computer Vision](https://www.marktechpost.com/2021/11/19/imperial-college-london-researchers-propose-a-novel-randomly-connected-neural-network-for-self-supervised-monocular-depth-estimation-in-computer-vision/)

### Synced: [SPANN: A Highly-Efficient Billion-Scale Approximate Nearest Neighbour Search That’s 2× Faster Than the SOTA Method](https://syncedreview.com/2021/11/19/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-148/)

## 2021-11-18

### Google AI: [Permutation-Invariant Neural Networks for Reinforcement Learning](http://ai.googleblog.com/2021/11/permutation-invariant-neural-networks.html)

## 2021-11-17

### Google AI: [Predicting Text Readability from Scrolling Interactions](http://ai.googleblog.com/2021/11/predicting-text-readability-from.html)

## 2021-11-16

### Synced: [Google Brain & Radboud U ‘Dive Into Chaos’ to Show Gradients Are Not All You Need in Dynamical Systems](https://syncedreview.com/2021/11/16/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-145/)

### MARKTECHPOST: [DeepMind Researchers Present The ‘One Pass ImageNet’ (OPIN) Problem To Study The Effectiveness Of Deep Learning In A Streaming Setting](https://www.marktechpost.com/2021/11/16/deepmind-researchers-present-the-one-pass-imagenet-opin-problem-to-study-the-effectiveness-of-deep-learning-in-a-streaming-setting/)

## 2021-11-15

### Google AI: [MetNet-2: Deep Learning for 12-Hour Precipitation Forecasting](http://ai.googleblog.com/2021/11/metnet-2-deep-learning-for-12-hour.html)

### Synced: [Google’s Pet Portraits Will Find Art Doubles for Your Pets](https://syncedreview.com/2021/11/15/googles-pet-portraits-will-find-art-doubles-for-your-pets/)

### :star:Synced: [A Leap Forward in Computer Vision: Facebook AI Says Masked Autoencoders Are Scalable Vision Learners](https://syncedreview.com/2021/11/15/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-144/)
## 2021-11-12

### :star:Synced: [DeepMind’s One Pass ImageNet: A New Benchmark for Resource Efficiency in Deep Learning](https://syncedreview.com/2021/11/12/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-143/)
## 2021-11-11

### Google AI: [Making Better Future Predictions by Watching Unlabeled Videos](http://ai.googleblog.com/2021/11/making-better-future-predictions-by.html)

## 2021-11-10

### Google AI: [Model Ensembles Are Faster Than You Think](http://ai.googleblog.com/2021/11/model-ensembles-are-faster-than-you.html)

## 2021-11-09

### Synced: [Can ViT Layers Express Convolutions? Peking U, UCLA & Microsoft Researchers Say ‘Yes’](https://syncedreview.com/2021/11/09/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-141/)

### MARKTECHPOST: [MIT AI Researchers Introduce ‘PARP’: A Method To Improve The Efficiency And Performance Of A Neural Network](https://www.marktechpost.com/2021/11/09/mit-ai-researchers-introduce-parp-a-method-to-improve-the-efficiency-and-performance-of-a-neural-network/)

## 2021-11-02

### MARKTECHPOST: [Researchers Propose ‘Projected-GANs’, To Improve Image Quality, Sample Efficiency, And Convergence Speed](https://www.marktechpost.com/2021/11/02/researchers-propose-projected-gans-to-improve-image-quality-sample-efficiency-and-convergence-speed/)
## 2021-11-04

### Synced: [Washington U & Google Study Reveals How Attention Matrices Are Formed in Encoder-Decoder Architectures](https://syncedreview.com/2021/11/04/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-138/)

## 2021-11-03

### :star:MARKTECHPOST: [MIT Researchers Propose A New Method To Prevent Shortcuts In Machine Learning Models By Forcing The Model To Use More Data In Its Decision-Making](https://www.marktechpost.com/2021/11/03/mit-researchers-propose-a-new-method-to-prevent-shortcuts-in-machine-learning-models-by-forcing-the-model-to-use-more-data-in-its-decision-making/)

### Google AI: [Self-Supervised Reversibility-Aware Reinforcement Learning](http://ai.googleblog.com/2021/11/self-supervised-reversibility-aware.html)

### Synced: [Twitter Cortex Proposes LMSOC for Socially Sensitive Pretraining](https://syncedreview.com/2021/11/03/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-137/)
## 2021-10-29

### Synced: [DeepMind Study Resolves Delusions in Sequence Models for Interaction and Control](https://syncedreview.com/2021/10/29/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-134/)

## 2021-10-28

### MARKTECHPOST: [Researchers Introduce ‘AugMax’: An Open-Sourced Data Augmentation Framework To Unify The Two Aspects Of Diversity And Hardness](https://www.marktechpost.com/2021/10/28/researchers-introduce-augmax-an-open-sourced-data-augmentation-framework-to-unify-the-two-aspects-of-diversity-and-hardness/)

## 2021-10-25

### :star:Google AI: [Deciding Which Tasks Should Train Together in Multi-Task Neural Networks](http://ai.googleblog.com/2021/10/deciding-which-tasks-should-train.html)

[[paper]](https://arxiv.org/pdf/2109.04617.pdf)

**Keywords**: Multi-task learning, meta-learning

**Summary**:

![img](assets/images/pages/tag-mtl.gif)

### Synced: [Facebook AI Releases SaLinA: A Flexible and Simple Library for Learning Sequential Agents](https://syncedreview.com/2021/10/25/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-130/)

### MARKTECHPOST: [Hugging Face Introduces “T0”, An Encoder-Decoder Model That Consumes Textual Inputs And Produces Target Responses](https://www.marktechpost.com/2021/10/25/hugging-face-introduces-t0-an-encoder-decoder-model-that-consumes-textual-inputs-and-produces-target-responses/)

## 2021-10-24

### MARKTECHPOST: [CMU AI Researchers Present A New Study To Achieve Fairness and Accuracy in Machine Learning Systems For Public Policy](https://www.marktechpost.com/2021/10/24/cmu-ai-researchers-present-a-new-study-to-achieve-fairness-and-accuracy-in-machine-learning-systems-for-public-policy/)

## 2021-10-21

### MARKTECHPOST: [AI Researchers From Huawei and Shanghai Jiao Tong University Introduce ‘CIPS-3D’: A 3D-Aware Generator of GANs](https://www.marktechpost.com/2021/10/21/ai-researchers-from-huawei-and-shanghai-jiao-tong-university-introduce-cips-3d-a-3d-aware-generator-of-gans/)

## 2021-10-20

### Google AI: [Predicting Spreadsheet Formulas from Semi-structured Contexts](http://ai.googleblog.com/2021/10/predicting-spreadsheet-formulas-from.html)

### Synced: [Yann LeCun Team Challenges Current Beliefs on Interpolation and Extrapolation Regarding DL Model Generalization Performance](https://syncedreview.com/2021/10/20/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-127/)

## 2021-10-19

### :star:Synced: [StyleNeRF: A 3D-Aware Generator for High-Resolution Image Synthesis with Explicit Style Control](https://syncedreview.com/2021/10/19/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-126/)

### MARKTECHPOST: [FlyingSquid: A Python Framework For Interactive Weak Supervision](https://www.marktechpost.com/2021/10/19/flyingsquid-a-python-framework-for-interactive-weak-supervision/)

## 2021-10-18

### Google AI: [How Underspecification Presents Challenges for Machine Learning](http://ai.googleblog.com/2021/10/how-underspecification-presents.html)

[[paper]](https://arxiv.org/pdf/2011.03395.pdf)

**keywords**: underspecification

**Summary**:

- **underspecification**: a key failure mode especially prevalent in modern ML systems
- Identifying Underspecification in Real Applications
  - Underspecification in Computer Vision
  - Underspecification in Other Applications

## 2021-10-16

### MARKTECHPOST: [Researchers at ETH Zurich & Microsoft Introduce ‘PixLoc’: A Neural Network For Feature Alignment With A 3D Model Of The Environment](https://www.marktechpost.com/2021/10/16/researchers-at-eth-zurich-microsoft-introduce-pixloc-a-neural-network-for-feature-alignment-with-a-3d-model-of-the-environment/)

## 2021-10-15

### Google AI: [SimVLM: Simple Visual Language Model Pre-training with Weak Supervision](http://ai.googleblog.com/2021/10/simvlm-simple-visual-language-model-pre.html)

### Synced: [Google Proposes ARDMs: Efficient Autoregressive Models That Learn to Generate in any Order](https://syncedreview.com/2021/10/15/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-124/)

## 2021-10-14

### :star:Google AI: [Baselines for Uncertainty and Robustness in Deep Learning](http://ai.googleblog.com/2021/10/baselines-for-uncertainty-and.html)

### :star:Synced: [Google Researchers Explore the Limits of Large-Scale Model Pretraining](https://syncedreview.com/2021/10/14/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-123/)

## 2021-10-13

### Google AI: [Self-Supervised Learning Advances Medical Image Classification](http://ai.googleblog.com/2021/10/self-supervised-learning-advances.html)

### Synced: [ICCV 2021 Best Papers Announced](https://syncedreview.com/2021/10/13/iccv-2021-best-papers-announced/)

[[Swin Transformer]](https://arxiv.org/pdf/2103.14030.pdf) [[Mip-NeRF]](https://arxiv.org/pdf/2103.13415.pdf) [[OpenGAN]](https://arxiv.org/pdf/2104.02939.pdf) [[Viewing Graph Solvability]](https://openaccess.thecvf.com/content/ICCV2021/papers/Arrigoni_Viewing_Graph_Solvability_via_Cycle_Consistency_ICCV_2021_paper.pdf) [[Common Objects in 3D]](https://arxiv.org/pdf/2109.00512.pdf) [[Pixel-Perfect Structure-from-Motion]](https://arxiv.org/pdf/2108.08291.pdf)

## 2021-10-12

### :star: Synced: [Are Patches All You Need? New Study Proposes Patches Are Behind Vision Transformers’ Strong Performance](https://syncedreview.com/2021/10/12/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-121/)

[[openreview]](https://openreview.net/forum?id=TVHS5Y4dNvM)

### :star:MARKTECHPOST: [NVIDIA AI Releases StyleGAN3: Alias-Free Generative Adversarial Networks](https://www.marktechpost.com/2021/10/12/nvidia-ai-releases-stylegan3-alias-free-generative-adversarial-networks/)

## 2021-10-08

### :star: Synced: [Apple Study Reveals the Learned Visual Representation Similarities and Dissimilarities Between Self-Supervised and Supervised Methods](https://syncedreview.com/2021/10/08/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-120/)

[[paper]](https://arxiv.org/pdf/2110.00528.pdf)

## 2021-10-06

### :star:Synced: [Google Significantly Improves Visual Representations by Adding Explicit Information Compression](https://syncedreview.com/2021/10/06/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-118/)

## 2021.09.30

### :star: Google AI: ​[Efficient Partitioning of Road Networks](http://ai.googleblog.com/2021/09/efficient-partitioning-of-road-networks.html)

## 2021.09.29

### :star: Google AI: [Improving Generalization in Reinforcement Learning using Policy Similarity Embeddings](http://ai.googleblog.com/2021/09/improving-generalization-in.html)

### :star: DeepMind: [Nowcasting the Next Hour of Rain](https://deepmind.com/blog/article/nowcasting)

### Synced: [NYU & UNC Reveal How Transformers’ Learned Representations Change After Fine-Tuning](https://syncedreview.com/2021/09/29/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-114/)

### MARKTECHPOST: [University of Oxford Researchers Release ‘PASS’ Dataset With 1.4M+ Images (Free From Humans) For Self-Supervised Machine Learning](https://www.marktechpost.com/2021/09/29/university-of-oxford-researchers-release-pass-dataset-with-1-4m-images-free-from-humans-for-self-supervised-machine-learning/)

## 2021.09.23

### Synced: [UMass Amherst & Google Improve Few-Shot Learning on NLP Benchmarks via Task Augmentation and Self-Training](https://syncedreview.com/2021/09/23/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-110/)

[[paper]](https://arxiv.org/pdf/2109.06270.pdf)

### Google AI: [High-Quality, Robust and Responsible Direct Speech-to-Speech Translation](http://ai.googleblog.com/2021/09/high-quality-robust-and-responsible.html)

[[paper]](https://arxiv.org/pdf/2107.08661.pdf)

## 2021.09.22

### :star:Google AI: [Pathdreamer: A World Model for Indoor Navigation](http://ai.googleblog.com/2021/09/pathdreamer-world-model-for-indoor.html)

[[paper]](https://arxiv.org/abs/2105.08756)

**Keywords**: indoor navigation

**Comment**: Super Cool!

## 2021.09.20

### :star:Synced: [DeepMind’s Bootstrapped Meta-Learning Enables Meta Learners to Teach Themselves](https://syncedreview.com/2021/09/20/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-107/)

## 2021.09.16

### :star:Google AI: [Toward Fast and Accurate Neural Networks for Image Recognition](http://ai.googleblog.com/2021/09/toward-fast-and-accurate-neural.html)

[[paper1: EfficientNetV2]](https://arxiv.org/pdf/2104.00298.pdf) [[paper2: CoAtNet]](https://arxiv.org/pdf/2106.04803.pdf) [[code]](https://github.com/google/automl)

**Keywords**: neural architecture search;

**Comment**: Super Cool!

### Synced: [UC Berkeley Uses a Causal Perspective to Formalise the Desiderata for Representation Learning](https://syncedreview.com/2021/09/16/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-105/)

[[paper]](https://arxiv.org/pdf/2109.03795.pdf)

**Keywords**: representation learning; non-spuriousness; disentanglement 

**Comment**: Too much terminology that I don‘t understand. Mark and read it later.

### MARKTECHPOST: [Israeli Researchers Unveil DeepSIM, a Neural Generative Model for Conditional Image Manipulation Based on a Single Image](https://www.marktechpost.com/2021/09/16/israeli-researchers-unveil-deepsim-a-neural-generative-model-for-conditional-image-manipulation-based-on-a-single-image/)

[[project page]](http://www.vision.huji.ac.il/deepsim/) [[paper]](https://arxiv.org/pdf/2109.06151.pdf) [[code]](https://github.com/eliahuhorwitz/DeepSIM)

**Comment**: Experiment results are astonishing. Mark and read later.

## 2021.09.15

### Google AI: [Revisiting Mask-Head Architectures for Novel Class Instance Segmentation](http://ai.googleblog.com/2021/09/revisiting-mask-head-architectures-for.html)

[[project page]](https://google.github.io/deepmac/) [[paper]](https://arxiv.org/pdf/2104.00613.pdf) [[partially supervised segmentation paper]](https://arxiv.org/pdf/1711.10370.pdf)

**Keywords**: instance segmentation; partially supervised instance segmentation

**Summary**: 

Instance segmentation is an important task to many downstream applications. Collecting large labeled instance segmentation dataset is time consuming. Partially supervised instance segmentation target to tackle the challenge but requires a **stronger form of model generalization** to handle **novel classes not seen at training time**. This paper proposed two easy-to-implement fixes (one training protocol fix, one mask-head architecture fix) based on Mask R-CNN like network that work in tandem to close the gap to fully supervised performance. *While neither of these ingredients have a large impact on the classes for which masks are available during training, employing both leads to significant improvement on novel classes for which masks are not available during training.* In a nutshell, **cropping exclusively to ground true boxes during training** and **using deep hourglass mask heads with 50 or more layers** brought significant performance improvement to unseen classes.

**Comment**: I haven't read the paper yet. I hope there will be more discussion about why these two fix would bring better performance to unseen classes. Otherwise it's just a technical report.

## 2021.09.09

### Google AI: [Personalized ASR Models from a Large and Diverse Disordered Speech Dataset](http://ai.googleblog.com/2021/09/personalized-asr-models-from-large-and.html)

[[paper1]](https://www.isca-speech.org/archive/interspeech_2021/macdonald21_interspeech.html) [[paper2]](https://www.isca-speech.org/archive/interspeech_2021/green21_interspeech.html)

**Keywords**: Automatic speech recognition (ASR)

**Summary**: 

With over 1 million utterances, Euphonia’s corpus is one of the largest and most diversely disordered speech corpora (in terms of disorder types and severities) and has enabled significant advances in ASR accuracy for these types of atypical speech. The results demonstrate the efficacy of personalized ASR models for recognizing a wide range of speech impairments and severities, with potential for making ASR available to a wider population of users.

## 2021.09.02

### :star:Google AI: [Discovering Anomalous Data with Self-Supervised Learning](http://ai.googleblog.com/2021/09/discovering-anomalous-data-with-self.html)

[[paper1]](https://arxiv.org/pdf/2011.02578.pdf) [[paper2: CutPaste]](https://arxiv.org/pdf/2104.04015.pdf) [[code]](https://github.com/google-research/deep_representation_one_class)

**Keywords**: anomaly detection; self-supervised learning; one-class classification

**Summary**: 

The assumption of anomaly detection or the abstract of the problem one-class classification is that you have a large amount of normal examples and only a few anomalous data. The first paper aims to combine traditional one-class classifier with self-supervised learning for feature extraction. A distribution augmentation (DA) method is proposed to separate outlier from inlier while contrastive learning tend to spread out normal examples uniformly on a sphere.

![](https://raw.githubusercontent.com/yuanpinz/blog/main/assets/images/pages/da.jpg)

The second paper is designed a cut and paste method for self-supervised learning.

![](https://raw.githubusercontent.com/yuanpinz/blog/main/assets/images/pages/cutpaste.gif)

**Comment**: With a fast glance of the blog, the idea of combining one-class classifier with self-learning feature extractor is trivial. The proposed distribution augmentation (DA) to separate outliers from inlier is interesting but lack of persuasion because the situation when both inliers and augmented data are uniformly spread out on a sphere isn't excluded. The second paper is more of an adaptation for defect detection of the first paper.  

## 2021.05.06

### :star:DeepMind: [Game theory as an engine for large-scale data analysis](https://deepmind.com/blog/article/EigenGame)

## 2021.03.25

### Andrew Ng: [A Chat with Andrew on MLOps: From Model-centric to Data-centric AI](https://www.youtube.com/watch?v=06-AZXmwHjo)

[[slide]](https://www.deeplearning.ai/wp-content/uploads/2021/06/MLOps-From-Model-centric-to-Data-centric-AI.pdf)

**Keywords**: data-centric

**Summary**:

MLOps’ most important task: Ensure consistently high-quality data in all phases of the ML project lifecycle. Good data is: 

- Defined consistently (definition of labels y is unambiguous) • Cover of important cases (good coverage of inputs x) 
- Has timely feedback from production data (distribution covers data drift and concept drift) 
- Sized appropriately

![image-20210917110503117](https://raw.githubusercontent.com/yuanpinz/blog/main/assets/images/pages/image-20210917110503117.png)

**Comment**: Like Andrew said in the webinar, we took 80% of time preparing high quality data but only 1% of AI research is about data. It would be more encouraging to see more researches about how data quality affect model performance.

## 2021.01.05

### :star:OpenAI: [CLIP: Connecting Text and Images](https://openai.com/blog/clip/)

### :star:OpenAI: [DALL·E: Creating Images from Text](https://openai.com/blog/dall-e/)

## 2020.06.17

### :star:OpenAI: [Image GPT](https://openai.com/blog/image-gpt/)

---

# Reddit/r/\<ML Topics\>

### r/MachineLearning: [[D] 5 considerations for Deploying Machine Learning Models in Production – what did I miss?](https://www.reddit.com/r/MachineLearning/comments/qz3qtv/d_5_considerations_for_deploying_machine_learning/)

> Posted by [u/mgalarny](https://www.reddit.com/user/mgalarny/)
>
> I wrote a post about [considerations for deploying machine learning models in production.](https://towardsdatascience.com/considerations-for-deploying-machine-learning-models-in-production-89d38d96cc23) Below are the considerations. What did I not consider? I know the first consideration seems obvious, but I thought it was worth mentioning.
>
> > [Charming-Fishing3155](https://www.reddit.com/user/Charming-Fishing3155/)
> >
> > So:
> >
> > 1. You do not need feature store, unless your model depends on real time feature values , I.e. values that occurred after the model was trained. Those are usually relate to time based information.
> > 2. You missed model fairness and bias measurements.
> > 3. You missed progressive deployment. Usually models are deployed in shadow mode or canary mode. This way you can compare the new model to the old model, before promotion.
> > 4. I would also recommend having some sort of a CD pipeline, such that the models are tested in production like env (e.g. staging) before placing them in production.
> > 5. Within the CI/CD you should design ML specific unit tests.
> > 6. Regarding monitoring, you should also monitor you data sources - e.g. general data quality, as well as latency, health, etc.
> > 7. You should have a mechanism such that models can be rolled back to previous versions.
> > 8. Note that there are two kinds of productions: real time and batch. Depending on your use case, you might want to consider your points as they relate to the batch use case.

### r/MachineLearning: [[D] Measure the distance between two domains for transfer learning.](https://www.reddit.com/r/MachineLearning/comments/qoqpv2/d_measure_the_distance_between_two_domains_for/)

> [apprximatelycorrect](https://www.reddit.com/user/apprximatelycorrect/)
>
> No, this is actually an active research area. You are, roughly asking, suppose you want to minimize F_P(t) := E_P[f(t, z)], in the parameter t. But instead you have samples Z ~ Q, where Q is not equal to P. Your question boils down to "how easy is it to optimize F_P(t), given sample access to Q"?.
>
> Of course some type of assumptions on the loss f, parameter space that t lies in, and the distribution pair (P, Q) will be necessary to make progress. Your question suggests one popular one, called covariate shift or domain adaptation, where Z = (X, Y) and the conditional distribution Y | X is fixed (i.e., it is the same) under P and Q, but the distribution on X is allowed to vary.
>
> To my knowledge there is not yet an established metric of difficulty in the above described situation. As you can imagine, it will not just depend on P, Q, but rather also the type of task being addressed (e.g., if f is a square loss, and t is a linear functional on the data, then this is like estimating a linear model with a different distribution on the covariates, so you would roughly expect the complexity to scale in tr(Cov_Q^{-1} Cov_P), where here tr is trace, and Cov_D is the expectation E_D[X X^T]. This is d (the dimension of the covariates) when P = Q.)
>
> You might also see: https://arxiv.org/pdf/1803.01833.pdf, this paper introduces one notion called the "transfer exponent".

### r/MachineLearning: [[D] What do Machine Learning Engineers at Facebook do?](https://www.reddit.com/r/MachineLearning/comments/qkyini/d_what_do_machine_learning_engineers_at_facebook/)

> [PresidentOfTacoTown](https://www.reddit.com/user/PresidentOfTacoTown/)
>
> I can speak to my observed experience of the difference between three broad categories of Machine Learning adjacent roles that I imagine exist at a company like Facebook:
>
> **Machine Learning Engineer (MLE)**: This is more of a software engineering "like" role. You work on writing internal tools (sometimes that get open-sourced) and creating machine learning pipelines and infrastructure. So for example you may have the task of appropriately designing and optimizing the ways in which data gets stored, loaded, and preprocessed in order or something like trying to optimally parallelize training jobs to tune hyperparameters and architectures, some of your responsibilities might be making sure that the model is packaged and deployed appropriately so that infra/DevOps teams can monitor and adequately control it so that it interacts with the appropriate interfaces that use those models
>
> **Data Scientist (DS):** Your job is more about very solving specific business problems with data. I know through friends that have this position, that at Facebook they do a lot of their work in Jupyter Notebooks, for the ease of sharing the results with say other DSs and MLEs. With Facebook (as with many larger tech companies) a lot of your work is going to be on building models for predict customer behavior in terms of advertisement engagement. Depending on your seniority you will get to propose and choose different approaches and data sources, but ultimately your models are a part of the product you're selling for FB ads services so you'll be doing lots of A/B tests and evaluating the results, and you will need to be able to "deliver" and spend a fair amount of your time explaining your approaches
>
> **Research Scientist (RS):** You work with Facebook's AI Research group, you present novel methods and approaches that will broadly focus on delivering and solving FB business problem but generally you get a little more flexibility and creative freedom to try new stuff. Your time is spent working on implementing your research and then often working with MLEs to set up your experiments after you have some initial proof of concept done. It's a little more open-ended than the DS position, but if your results are promising you might find that your also working with DSs to see your working go into production.
>
> 
>
> Hope this helps, but I recommend looking at the different roles they have on their job sites and also look for similarly titled positions at comparably sized companies, these often have a tremendous amount of overlap.
>
> 
>
> As others have mentioned though the recruiter will likely be able to answer your questions as well.

### r/MachineLearning: [[D] How would you deploy an optimization type model? ex: CLIP+VQGAN](https://www.reddit.com/r/MachineLearning/comments/qckgsj/d_how_would_you_deploy_an_optimization_type_model/)

> [Mefaso](https://www.reddit.com/user/Mefaso/)·[22h](https://www.reddit.com/r/MachineLearning/comments/qckgsj/comment/hhgr3oj/?utm_source=reddit&utm_medium=web2x&context=3)
>
> I actually spent other a month back in February setting something like that up.
>
> It's definitely doable, but for me the biggest issue was too slow startup times in EC2 instance for scaling.
>
> After a lot of optimization it would still take 4 minutes from requesting an instance to generation starting, which was too long to be practical for me
>
> > [gramhagen](https://www.reddit.com/user/gramhagen/)·[16h](https://www.reddit.com/r/MachineLearning/comments/qckgsj/comment/hhhhuf6/?utm_source=reddit&utm_medium=web2x&context=3)
> >
> > These are not scalable examples but I spent the last week hacking on two prototypes for hosting vqgan+clip which might be helpful
> >
> > 1. https://github.com/gramhagen/imagen - a unity application that hits a back-end server hosting vqgan+clip model
> > 2. [https://github.com/gramhagen/image](https://github.com/gramhagen/imagen) - a streamlit application for interacting with a vqgan+clip model
> >
> > Thoughts for how you might scale this would be to serve this model using something like [Ray Serve](https://docs.ray.io/en/latest/serve/index.html) on a cluster of workers with GPUs. you still need to handle asychronous requests though because the inference time is going to be too long unless you have a really small image and limited iterations. The hacky way I did it was just respond to the initial request with an id, and then have a second endpoint that retrieves images once they are ready.

### r/datascience: [Interviewing Red Flag Terms](https://www.reddit.com/r/datascience/comments/qc6nok/interviewing_red_flag_terms/)

> Posted by [Job Search](https://www.reddit.com/r/datascience/search?q=flair_name%3A"Job Search"&restrict_sr=1)
>
> Phrases that interviewers use that are red flags.
>
> So far I’ve noticed:
>
> 1. Our team is like the Navy Seals in within the company
> 2. work hard play hard
> 3. (me asking does your team work nights and weekends): We choose to because we are passionate about the work

### r/MachineLearning: [[D] Has the ResNet Hypothesis been debunked?](https://www.reddit.com/r/MachineLearning/comments/px3hzd/d_has_the_resnet_hypothesis_been_debunked/)

> Posted by
>
> [u/Ok_Slice4231](https://www.reddit.com/user/Ok_Slice4231/)
>
> The **ResNet architecture** was invented to solve the *degradation problem* that has been empirically seen in Very Deep Neural Networks i.e. “34-layer plain net has higher training error throughout the whole training procedure, even though the solution space of the 18-layer plain network is a subspace of that of the 34-layer one.“
>
> [![r/MachineLearning - [D\] Has the ResNet Hypothesis been debunked?](https://preview.redd.it/7todt74s18q71.png?width=1314&format=png&auto=webp&s=0a1af475ef27fd8355d1527223e74556c6a993e9)](https://preview.redd.it/7todt74s18q71.png?width=1314&format=png&auto=webp&s=0a1af475ef27fd8355d1527223e74556c6a993e9)
>
> The natural presumption is that this problem is caused by the **Vanishing Gradient Problem** which has been observed in Recurrent Neural Networks and, to a lesser extent, in Long-Short Term Memory Networks. But the authors of the paper argue that this is, *most likely,* not the case:
>
> > We argue that this optimization difficulty is unlikely to be caused by vanishing gradients. These plain networks are trained with BN [16], which ensures forward propagated signals to have non-zero variances. We also verify that the backward propagated gradients exhibit healthy norms with BN. So neither forward nor backward signals vanish. In fact, the 34-layer plain net is still able to achieve compet- itive accuracy (Table 3), suggesting that the solver works to some extent. We conjecture that the deep plain nets may have exponentially low convergence rates, which impact the reducing of the training error3. The reason for such optimization difficulties will be studied in the future.
>
> I will refer to this as the **“ResNet Hypothesis”**.
>
> Many recent papers and tutorials appear to be *assuming* that the ResNet Hypothesis is **false.** I have read numerous papers in which the authors add skip connections in order to *“improve gradient flow”* and they cite the original ResNet paper to support this claim. While it is quite plausible that adding skip connections will improve gradient flow, what caused the degradation problem in the **first place**? The idea that skip connections solve the degradation problem by improving gradient flow seems to be in *clear contradiction* with the ResNet Hypothesis; so where did this idea come from? ***Has the ResNet Hypothesis been*** ~~***debunked***~~ ***falsified******?***
>
> Edit 1 - I think this is an accurate representation of the average DL researcher’s (myself included) understanding of why ResNets work [based on [u/impossiblefork](https://www.reddit.com/u/impossiblefork/)’s [answer](https://www.reddit.com/r/MachineLearning/comments/px3hzd/comment/hekymwd/?utm_source=share&utm_medium=web2x&context=3)]:
>
> [![r/MachineLearning - [D\] Has the ResNet Hypothesis been debunked?](https://preview.redd.it/wbvvkwlrd8q71.png?width=724&format=png&auto=webp&s=7b3cac7d8baea007d9dd379ce67020a5a65e2c9b)](https://preview.redd.it/wbvvkwlrd8q71.png?width=724&format=png&auto=webp&s=7b3cac7d8baea007d9dd379ce67020a5a65e2c9b)
>
> Edit 2 - Apologies for using the word ”debunked” in the original post. Quite irresponsible of me in hindsight. Thanks to [/u/ComplexColor](https://www.reddit.com/u/ComplexColor/) for [pointing it out](https://www.reddit.com/r/MachineLearning/comments/px3hzd/comment/hemcuq0/?utm_source=share&utm_medium=web2x&context=3). Unfortunately I am unable to edit the title.
>
> > [BeatLeJuce](https://www.reddit.com/user/BeatLeJuce/)
> >
> > Shortcut connections improve the loss landscape; they make optimization much easier. There is a lot of research to back this up, but the two main papers that come to mind are
> >
> > - [The Shattered Gradients Problem: If resnets are the answer, then what is the question? (ICML 2017)](https://arxiv.org/abs/1702.08591) shows that ResNets have much more stable gradients.
> > - [Visualizing the Loss Landscape of Neural Nets (NeurIPS 2018)](https://proceedings.neurips.cc/paper/2018/hash/a41b3bb3e6b050b6c9067c67f663b915-Abstract.html) again shows that ResNets have a smoother loss surface (Figure 1 in that paper is the 1-picture-answer of your question).
> >
> > You don't *need* shortcuts to learn effective representations, but optimization will be harder. For example, [Fixup Initialization: Residual Learning Without Normalization (ICLR 2019)](https://arxiv.org/abs/1901.09321) shows that if you are careful about initialization, you can train ResNets without shortcuts to good results. [RepVGG: Making VGG-style ConvNets Great Again (CVPR 2021) ](https://arxiv.org/abs/2101.03697)shows that you can remove shortcuts *after training* and still have a good network.
> >
> > This is, BTW, still somewhat in line with the original idea of ResNet: You initialize each block as an identity function, so initially it almost appears as if the parameters aren't actually there / aren't doing anything. And then you gradually move away and have the effect of the block come into play.

### r/MachineLearning: [[D] What are some ideas that are hyped up in machine learning research but don't actually get used in industry (and vice versa)?](https://www.reddit.com/r/MachineLearning/comments/q86kqn/d_what_are_some_ideas_that_are_hyped_up_in/)

> [IntelArtiGen](https://www.reddit.com/user/IntelArtiGen/)
>
> **Cool in industry but not cool in research:** Cleaning datasets, going from dev to prod (and all the research to improve these processes)
>
> **Cool in research but not cool in industry:** Adversarial attacks
>
> just my opinion
>
> > [du_dt](https://www.reddit.com/user/du_dt/)
> >
> > About adversarial attacks in production: company wanted to insert adversarial noise in car sale ads posted on their site in order to break their competitors data scraping model (competitors just copied data from the original site). I think that’s awesome!
> >
> > The original article is in Russian, but the images are quite illustrative, try google translate
> >
> > https://habr.com/ru/company/avito/blog/452142/
> >
> > UPD: noise was inserted in photos, competitors tried to replace the watermark with theirs

### r/datascience: [Putting ML models in production](https://www.reddit.com/r/datascience/comments/q7zuxn/putting_ml_models_in_production/)

> [proverbialbunny](https://www.reddit.com/user/proverbialbunny/)
>
> The topic is complex, which is why there are multiple job roles that specialize in production and deployment. Some of them are Data Engineer, Infrastructure Software Engineer, and ML Engineer.
>
> How to productionize and deploy depends on what the model is doing and how it needs to get its data. On the input side there is batch, micro-batch, streaming, and REST. On the output side there is outputting to a DB, returning a REST request, creating a dashboard, and creating a report.
>
> All of these have different requirements. Furthermore, training and testing on your local machine may not be big data, but say the company grows to have enough customers it becomes big data in prod. Suddenly you realize you should have been using different tools the entire time.
>
> There are different services that aid the functionality of productionization and deployment. All of them have their strengths and weaknesses. I like to think of them as a spectrum between how much they handle the low level data engineering work for you to how bare metal they are. The ones that make life easiest may lack functionality you need, or may cost the most. The ones that are the most bare metal you can do anything and everything in but you have to setup an entire ecosystem of servers and pipes to get it all done becoming a full time job. Also, you need someone on call if a server goes down or breaks. This is why you want at least one Data Engineer, ML Engineer, Infrastructure Engineer, DevOps, or MLOps for the extreme situations where the server is on fire and someone who appropriately needs to handle that situation to minimize downtime.
>
> On the easiest to use side is Domino's Data Labs. It supports everything except dynamic scaling of Spark clusters on a heavy load, so if you're very big data it may not support it.
>
> On the next easiest but more powerful is Databricks. Already you're looking at a product designed to be learned before used. Databricks uses Spark, so it's designed for big data but is not necessary.
>
> Next easiest is the competition, like AWS Sagemaker. Out of the box the default functionality is more limited on these kinds of offerings unless you expand to using their entire ecosystem. How do you know what to parts of their ecosystem to choose that is right for you? Study alone typically doesn't do it by this point, you have to talk to an AWS rep, possibly multiple, and they will try to help you out.
>
> At the bottom is straight bare metal. Spin up your own servers in the cloud, install the necessary parts, and set it up yourself. The upside is this at first seems less complex. The downside is you're not forced to use best practices which will cause a lot of headaches down the road. You'll have a lot of limited functionality you didn't know could exist if you didn't use one of the offerings above that bundle tools together for you.

### r/datascience: [Who has left data science and analytics? What are you up to now?](https://www.reddit.com/r/datascience/comments/q75ce8/who_has_left_data_science_and_analytics_what_are/)

> Posted by [u/jehan_gonzales](https://www.reddit.com/user/jehan_gonzales/)
>
> I moved on from analytics two years ago and became a product manager.
>
> I was a data analyst for four years.
>
> 1. Almost two years in market research with survey data building statistical models (mainly linear and logistic regression) in SPSS and Excel (with a bit of R here and there)
> 2. Nine months managing a SQL database where I was meant to be analysing the data but was mainly debugging a very bad production environment
> 3. 1.5 years as a data analyst in product analytics where I worked with retail sales and loyalty program data. I spent the first year doing data governance stuff with the client but later moved into an ML team and tried to figure out insights for end users without them having to search for them.
>
> Since becoming a product manager, I can still work with data and do the interesting analysis but then I spend most of my time using the numbers to drive decisions and if there is anything that requires long, time consuming ETL tasks, I can farm them out.
>
> So far, it's been a great move as I've always been more interested in decision science rather than writing code for the sake of it (I enjoy it in moderation but find more meaning using analysis to get shit done).
>
> I was wondering, have any of you moved out of analytics and data science? What prompted the move? Or are you thinking about changing industries?
>
> Always interesting to hear from other people at the coalface.

### r/datascience: [Advice to all job seekers: be as critical to the company as they are to you](https://www.reddit.com/r/datascience/comments/puh45x/advice_to_all_job_seekers_be_as_critical_to_the/)

> Posted by [u/the75th](https://www.reddit.com/user/the75th/)
>
> Been seeing a lot of posts recently of people being hired to do data science and ending up in, from a data point of view, suboptimal work places. In my opinion many of these places had red flags from to get go based on the description of the company they gave.
>
> My main advice is to be as critical to the company as they are to you:
>
> Screen their job posting with as much rigour as they screen your CV trying to get a sense of what you'll *really* be doing irrespective of your 'data scientist' job title. Typical red flags for me would be (not exhaustive):
>
> - No mention of cloud related tooling.
> - SQL and data warehousing featuring more promintently than anything else. Reason being that if I wanted to do a DA job, which I really enjoyed from past experiences, I would just apply for that.
> - No mention of any kind of version control.
> - "Use whatever tools and languages you want on the job". This one is very particular but to me that would indicate no standardisation, probably a lot of csv files, excel users, ad-hoc analysis on notebooks and very little being put into production / automated. This might be a pet peeve but I believe in many cases long term value from data can't *just* be done through ad-hoc analyses and 99 % of companies aren't mature enough to let everyone use their own tools without it becoming an unmaintanable mess.
> - No mention of anything casual. This one is personal, colleagues are colleagues and not necessarily friends but a workplace with a few social amenities would make being 8-9 hours in the office more bearable.
>
> Not all of the information you value can be gotten from the job posting so the next step would be to think about what you value ahead of the interview and ask them in a polite manner. Job interviews should be as much of you deciding if they are a fit for you as vice versa.
>
> This may help you to uncover small details that can help you decide picking one offer over the other. Even if you only have 1 offer knowing what you're getting into in advance can help you make peace with / prepare for it.

> [Trylks](https://www.reddit.com/user/Trylks/)
>
> If I discard all places with red flags, I will only be able to work for myself, which is not necessarily a bad thing, but may not be for everyone.
>
> Note: as a freelancer, consultant, etc. you are still working for your clients, and they show red flags just the same.
>
> WRT OPs red flags, I only agree on the second (SQL), as a freelancer / consultant you are expected to "be on your own" on those points, i.e. those are not red flags to me.
>
> What are red flags for me? Off the top of my head:
>
> - Unrealistic expectations (the parent of all): "we want you to build and train GPT-4 for us, for $5000, in two weeks".
> - Micromanagement: "We have already decided what we are going to do and how we are going to do it. We want to hire you to apply linear regression to find a number between 3 and 5 that will magically make our decisions the right decisions. We do not know why the last 5 data scientists rejected to do a simple linear regression".
> - Lack of maturity: "We do not have any data. We want to hire you do do data science for us. Any advanced enough technology is like magic, we want you to show us your divination powers."

### r/datascience: [Data science even at mature companies can be a mixed bag.](https://www.reddit.com/r/datascience/comments/pu1y72/data_science_even_at_mature_companies_can_be_a/)

> Posted by [u/__compactsupport__](https://www.reddit.com/user/__compactsupport__/)
>
> Earned a full time position at a bank in their Financial Crime team preventing traders from manipulating the market. They said they had lots of data (they do) and wanted to incorporate some machine learning into their business. Sweet, I'm in.
>
> Its been rough. The team is a year old, they are mostly focused on making the product work rather than anything else, everything is run through KX and the q language (which is cool if you're into trading but a nightmare if you want to do analytics or ML).
>
> I've been given extremely easy to answer questions but the business insists I use ML because that's why they hired me. "Tell me when a trader makes a trade in a new sector" -- my guy, that is a look and not a problem for machine learning. I'd love to answer these questions, but because I'm at a bank things are extremely slow to move on anything. Getting a data store for analytics is a months long endeavour leaving me to use .csv files. I can't scale that.
>
> Gets better. I tried asking to talk to some of the people using our product so I could identify pain points and how we could solve that. Got a big fat "NOPE" and actually initiated an argument between my manager and the business owner.
>
> There is also nowhere for us to centralize our analytics work. No feature store, no data science sandbox, no data engineering to give us up to date info. I don't even have access to production data! All I get is staging which I have been assured is fit fur purpose \s.
>
> I'm frustrated. Its been 5 months or so, I think that is long enough to say "hey, not a good fit" and maybe find another position. Its a real shame because I worked in a different team at the same bank and they were much more mature with respect to data science.

### r/MachineLearning: [[Discussion] How to present machine learning projects to domain experts without ML background?](https://www.reddit.com/r/MachineLearning/comments/pph0ak/discussion_how_to_present_machine_learning/)

>[Screye](https://www.reddit.com/user/Screye/)
>
>I do thos frequently in my current job. The key is to get them interested in the problen and the solution.
>
>At a very high level, first convey these points briefly:
>
>1. The use case (what was the user workflow like before)
>2. The problem or the bottleneck or what you couldnt do before.
>3. Why and how the problem affects the user workflow (or why should i care )
>4. Mention that you have solved / addressed / bettered it
>5. Why no one else has solved it or why it is a hard problem
>6. So how did we do it ? A laymans menton of what the solution is
>
>So now they are hooked. You can now do a deep dive.
>
>Ideally a highly archtectural / flowchart of each module in the splution helps set the visual grounding needed to understand a deep technical solution.
>
>Then begin the deepdive. Tie every aspect of the deepdive with which module in the flowchart you're in.
>
>Lastly, assume your audience knows nothing. This leads to issues with runtime of the presentation. So my solution is to always have hidden faqs and explainer slides ready if needed. Read the room as you go and stop frequently for questions. This way you can keep up a good pace, and slowdown if there are a lot of question or even worse No Questions.
>
>Lqstly, qlways have a takeaways slide. After a 1 hr presentation some peoples brains are fried. So you want them to take the main takeaways even if they zoned out at some point. It also makes them feel like they took something awayy from the presentation and makes them more likely to attend future ones.
>
>Hope this helps.

### r/datascience: [Any Data Scientists here working for Microsoft or Amazon?](https://www.reddit.com/r/datascience/comments/pp2htw/any_data_scientists_here_working_for_microsoft_or/)

> [leatherarmor](https://www.reddit.com/user/leatherarmor/)
>
> I joined Amazon as a Data Scientist a few months ago in NYC.
>
> 1. **What kinds of projects are you working on as a data scientist?** Have you ever seen a product on Amazon that has only one photo, no text, and looks "fake"? Our team is working to help sellers improve their product listings. Our team builds models that are trained on and score the entire Amazon catalogue. We serve recommendations to sellers, e.g. "add 4+ photos". I'm currently building tracking to measure the impact of our product and concurrently performing causal inference studies on existing integrations.
> 2. **How have you grown as a data scientist since joining your company?** I barely knew AWS services before I joined, and I've been learning these services left and right since then. I enjoy the software and data engineering aspect of DS. One perk of working for Amazon is that you get all the AWS access you need.
> 3. **How does your company measure success of your projects?** No idea, but I don't think there's a simple answer. Generally speaking, it seems like you need to validate your own results and present them to a room of other scientists in what resembles peer review.
> 4. **How much corporate red tape do you have to deal with?** Almost zero. It's actually quite remarkable. Amazon is notorious for moving fast and not requiring signoff or permission for most things. They actively promote "bias for action" within the company. As far as I can tell, it is part of the culture.
> 5. **How much autonomy do you have? (For example to pursue a hunch where there is a potential for improvement even if no one notices or cares)** Lots. I'm treated far more senior than I was at my previous company. I report to one person and that's my manager. He listens to me on science topics and generally gives me ample control over what I am doing.
> 6. **What would you change about your company?** Amazon has some legacy internal tooling (outside AWS) that can be quite painful to work with. I also wish it was easier to use open source. It's certainly possible, but not always as easy as it should be.
> 7. **What's the remote work policy?** Atm, we are full remote. Starting in January, official policy from the top down is 3 days in, 2 days remote, although that might change.
> 8. **How's your work life balance?** So far great, but I'm still new. I think the long term answer is good not great. It's better than a startup, but there are big scary deadlines that you need to meet. FYI being a DS is quite a bit better than being a Data Engineer, because you won't be on call.
