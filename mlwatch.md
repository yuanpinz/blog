---
layout: page
title: ML Watch
key: page-mlwatch 
---

# Reddit/r/\<ML Topics\>

## r/datascience: [Data science even at mature companies can be a mixed bag.](https://www.reddit.com/r/datascience/comments/pu1y72/data_science_even_at_mature_companies_can_be_a/)

> Posted by
>
> [u/__compactsupport__](https://www.reddit.com/user/__compactsupport__/)
>
> Earned a full time position at a bank in their Financial Crime team preventing traders from manipulating the market. They said they had lots of data (they do) and wanted to incorporate some machine learning into their business. Sweet, I'm in.
>
> Its been rough. The team is a year old, they are mostly focused on making the product work rather than anything else, everything is run through KX and the q language (which is cool if you're into trading but a nightmare if you want to do analytics or ML).
>
> I've been given extremely easy to answer questions but the business insists I use ML because that's why they hired me. "Tell me when a trader makes a trade in a new sector" -- my guy, that is a look and not a problem for machine learning. I'd love to answer these questions, but because I'm at a bank things are extremely slow to move on anything. Getting a data store for analytics is a months long endeavour leaving me to use .csv files. I can't scale that.
>
> Gets better. I tried asking to talk to some of the people using our product so I could identify pain points and how we could solve that. Got a big fat "NOPE" and actually initiated an argument between my manager and the business owner.
>
> There is also nowhere for us to centralize our analytics work. No feature store, no data science sandbox, no data engineering to give us up to date info. I don't even have access to production data! All I get is staging which I have been assured is fit fur purpose \s.
>
> I'm frustrated. Its been 5 months or so, I think that is long enough to say "hey, not a good fit" and maybe find another position. Its a real shame because I worked in a different team at the same bank and they were much more mature with respect to data science.

## r/MachineLearning: [[Discussion] How to present machine learning projects to domain experts without ML background?](https://www.reddit.com/r/MachineLearning/comments/pph0ak/discussion_how_to_present_machine_learning/)

>[Screye](https://www.reddit.com/user/Screye/)
>
>I do thos frequently in my current job. The key is to get them interested in the problen and the solution.
>
>At a very high level, first convey these points briefly:
>
>1. The use case (what was the user workflow like before)
>2. The problem or the bottleneck or what you couldnt do before.
>3. Why and how the problem affects the user workflow (or why should i care )
>4. Mention that you have solved / addressed / bettered it
>5. Why no one else has solved it or why it is a hard problem
>6. So how did we do it ? A laymans menton of what the solution is
>
>So now they are hooked. You can now do a deep dive.
>
>Ideally a highly archtectural / flowchart of each module in the splution helps set the visual grounding needed to understand a deep technical solution.
>
>Then begin the deepdive. Tie every aspect of the deepdive with which module in the flowchart you're in.
>
>Lastly, assume your audience knows nothing. This leads to issues with runtime of the presentation. So my solution is to always have hidden faqs and explainer slides ready if needed. Read the room as you go and stop frequently for questions. This way you can keep up a good pace, and slowdown if there are a lot of question or even worse No Questions.
>
>Lqstly, qlways have a takeaways slide. After a 1 hr presentation some peoples brains are fried. So you want them to take the main takeaways even if they zoned out at some point. It also makes them feel like they took something awayy from the presentation and makes them more likely to attend future ones.
>
>Hope this helps.

## r/datascience: [Any Data Scientists here working for Microsoft or Amazon?](https://www.reddit.com/r/datascience/comments/pp2htw/any_data_scientists_here_working_for_microsoft_or/)

> [leatherarmor](https://www.reddit.com/user/leatherarmor/)
>
> I joined Amazon as a Data Scientist a few months ago in NYC.
>
> 1. **What kinds of projects are you working on as a data scientist?** Have you ever seen a product on Amazon that has only one photo, no text, and looks "fake"? Our team is working to help sellers improve their product listings. Our team builds models that are trained on and score the entire Amazon catalogue. We serve recommendations to sellers, e.g. "add 4+ photos". I'm currently building tracking to measure the impact of our product and concurrently performing causal inference studies on existing integrations.
> 2. **How have you grown as a data scientist since joining your company?** I barely knew AWS services before I joined, and I've been learning these services left and right since then. I enjoy the software and data engineering aspect of DS. One perk of working for Amazon is that you get all the AWS access you need.
> 3. **How does your company measure success of your projects?** No idea, but I don't think there's a simple answer. Generally speaking, it seems like you need to validate your own results and present them to a room of other scientists in what resembles peer review.
> 4. **How much corporate red tape do you have to deal with?** Almost zero. It's actually quite remarkable. Amazon is notorious for moving fast and not requiring signoff or permission for most things. They actively promote "bias for action" within the company. As far as I can tell, it is part of the culture.
> 5. **How much autonomy do you have? (For example to pursue a hunch where there is a potential for improvement even if no one notices or cares)** Lots. I'm treated far more senior than I was at my previous company. I report to one person and that's my manager. He listens to me on science topics and generally gives me ample control over what I am doing.
> 6. **What would you change about your company?** Amazon has some legacy internal tooling (outside AWS) that can be quite painful to work with. I also wish it was easier to use open source. It's certainly possible, but not always as easy as it should be.
> 7. **What's the remote work policy?** Atm, we are full remote. Starting in January, official policy from the top down is 3 days in, 2 days remote, although that might change.
> 8. **How's your work life balance?** So far great, but I'm still new. I think the long term answer is good not great. It's better than a startup, but there are big scary deadlines that you need to meet. FYI being a DS is quite a bit better than being a Data Engineer, because you won't be on call.

---


# Machine Learning Researches

## 2021.09.23

### Synced: [UMass Amherst & Google Improve Few-Shot Learning on NLP Benchmarks via Task Augmentation and Self-Training](https://syncedreview.com/2021/09/23/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-110/)

[[paper]](https://arxiv.org/pdf/2109.06270.pdf)

### Google AI: [High-Quality, Robust and Responsible Direct Speech-to-Speech Translation](http://ai.googleblog.com/2021/09/high-quality-robust-and-responsible.html)

[[paper]](https://arxiv.org/pdf/2107.08661.pdf)

## 2021.09.22

### :star:Google AI: [Pathdreamer: A World Model for Indoor Navigation](http://ai.googleblog.com/2021/09/pathdreamer-world-model-for-indoor.html)

[[paper]](https://arxiv.org/abs/2105.08756)

**Keywords**: indoor navigation

**Comment**: Super Cool!

## 2021.09.20

### :star:Synced: [DeepMind’s Bootstrapped Meta-Learning Enables Meta Learners to Teach Themselves](https://syncedreview.com/2021/09/20/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-107/)



## 2021.09.16

### :star:Google AI: [Toward Fast and Accurate Neural Networks for Image Recognition](http://ai.googleblog.com/2021/09/toward-fast-and-accurate-neural.html)

[[paper1: EfficientNetV2]](https://arxiv.org/pdf/2104.00298.pdf) [[paper2: CoAtNet]](https://arxiv.org/pdf/2106.04803.pdf) [[code]](https://github.com/google/automl)

**Keywords**: neural architecture search;

**Comment**: Super Cool!

### Synced: [UC Berkeley Uses a Causal Perspective to Formalise the Desiderata for Representation Learning](https://syncedreview.com/2021/09/16/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-105/)

[[paper]](https://arxiv.org/pdf/2109.03795.pdf)

**Keywords**: representation learning; non-spuriousness; disentanglement 

**Comment**: Too much terminology that I don‘t understand. Mark and read it later.

### Marktechpost: [Israeli Researchers Unveil DeepSIM, a Neural Generative Model for Conditional Image Manipulation Based on a Single Image](https://www.marktechpost.com/2021/09/16/israeli-researchers-unveil-deepsim-a-neural-generative-model-for-conditional-image-manipulation-based-on-a-single-image/)

[[project page]](http://www.vision.huji.ac.il/deepsim/) [[paper]](https://arxiv.org/pdf/2109.06151.pdf) [[code]](https://github.com/eliahuhorwitz/DeepSIM)

**Comment**: Experiment results are astonishing. Mark and read later.

## 2021.09.15

### Google AI: [Revisiting Mask-Head Architectures for Novel Class Instance Segmentation](http://ai.googleblog.com/2021/09/revisiting-mask-head-architectures-for.html)

[[project page]](https://google.github.io/deepmac/) [[paper]](https://arxiv.org/pdf/2104.00613.pdf) [[partially supervised segmentation paper]](https://arxiv.org/pdf/1711.10370.pdf)

**Keywords**: instance segmentation; partially supervised instance segmentation

**Summary**: 

Instance segmentation is an important task to many downstream applications. Collecting large labeled instance segmentation dataset is time consuming. Partially supervised instance segmentation target to tackle the challenge but requires a **stronger form of model generalization** to handle **novel classes not seen at training time**. This paper proposed two easy-to-implement fixes (one training protocol fix, one mask-head architecture fix) based on Mask R-CNN like network that work in tandem to close the gap to fully supervised performance. *While neither of these ingredients have a large impact on the classes for which masks are available during training, employing both leads to significant improvement on novel classes for which masks are not available during training.* In a nutshell, **cropping exclusively to ground true boxes during training** and **using deep hourglass mask heads with 50 or more layers** brought significant performance improvement to unseen classes.

**Comment**: I haven't read the paper yet. I hope there will be more discussion about why these two fix would bring better performance to unseen classes. Otherwise it's just a technical report.

## 2021.09.09

### Google AI: [Personalized ASR Models from a Large and Diverse Disordered Speech Dataset](http://ai.googleblog.com/2021/09/personalized-asr-models-from-large-and.html)

[[paper1]](https://www.isca-speech.org/archive/interspeech_2021/macdonald21_interspeech.html) [[paper2]](https://www.isca-speech.org/archive/interspeech_2021/green21_interspeech.html)

**Keywords**: Automatic speech recognition (ASR)

**Summary**: 

With over 1 million utterances, Euphonia’s corpus is one of the largest and most diversely disordered speech corpora (in terms of disorder types and severities) and has enabled significant advances in ASR accuracy for these types of atypical speech. The results demonstrate the efficacy of personalized ASR models for recognizing a wide range of speech impairments and severities, with potential for making ASR available to a wider population of users.

## 2021.09.02

### :star:Google AI: [Discovering Anomalous Data with Self-Supervised Learning](http://ai.googleblog.com/2021/09/discovering-anomalous-data-with-self.html)

[[paper1]](https://arxiv.org/pdf/2011.02578.pdf) [[paper2: CutPaste]](https://arxiv.org/pdf/2104.04015.pdf) [[code]](https://github.com/google-research/deep_representation_one_class)

**Keywords**: anomaly detection; self-supervised learning; one-class classification

**Summary**: 

The assumption of anomaly detection or the abstract of the problem one-class classification is that you have a large amount of normal examples and only a few anomalous data. The first paper aims to combine traditional one-class classifier with self-supervised learning for feature extraction. A distribution augmentation (DA) method is proposed to separate outlier from inlier while contrastive learning tend to spread out normal examples uniformly on a sphere.

![](https://raw.githubusercontent.com/yuanpinz/blog/main/assets/images/pages/da.jpg)

The second paper is designed a cut and paste method for self-supervised learning.

![](https://raw.githubusercontent.com/yuanpinz/blog/main/assets/images/pages/cutpaste.gif)

**Comment**: With a fast glance of the blog, the idea of combining one-class classifier with self-learning feature extractor is trivial. The proposed distribution augmentation (DA) to separate outliers from inlier is interesting but lack of persuasion because the situation when both inliers and augmented data are uniformly spread out on a sphere isn't excluded. The second paper is more of an adaptation for defect detection of the first paper.  

## 2021.05.06

### :star:DeepMind: [Game theory as an engine for large-scale data analysis](https://deepmind.com/blog/article/EigenGame)

**Keywords**: 

**Summary**:

## 2021.03.25

### Andrew Ng: [A Chat with Andrew on MLOps: From Model-centric to Data-centric AI](https://www.youtube.com/watch?v=06-AZXmwHjo)

[[slide]](https://www.deeplearning.ai/wp-content/uploads/2021/06/MLOps-From-Model-centric-to-Data-centric-AI.pdf)

**Keywords**: data-centric

**Summary**:

MLOps’ most important task: Ensure consistently high-quality data in all phases of the ML project lifecycle. Good data is: 

- Defined consistently (definition of labels y is unambiguous) • Cover of important cases (good coverage of inputs x) 
- Has timely feedback from production data (distribution covers data drift and concept drift) 
- Sized appropriately

![image-20210917110503117](https://raw.githubusercontent.com/yuanpinz/blog/main/assets/images/pages/image-20210917110503117.png)

**Comment**: Like Andrew said in the webinar, we took 80% of time preparing high quality data but only 1% of AI research is about data. It would be more encouraging to see more researches about how data quality affect model performance.

## 2021.01.05

### :star:OpenAI: [CLIP: Connecting Text and Images](https://openai.com/blog/clip/)

**Keywords**: 

**Summary**:

### :star:OpenAI: [DALL·E: Creating Images from Text](https://openai.com/blog/dall-e/)

**Keywords**: 

**Summary**:

## 2020.06.17

### :star:OpenAI: [Image GPT](https://openai.com/blog/image-gpt/)

**Keywords**: 

**Summary**:

